{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsKQBjNuLYny",
        "outputId": "b54a10a4-5073-4d81-95ce-5d094cc02e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating stratified samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2728491562.py:35: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  stratified_sample = df.groupby(\"strat_key\", group_keys=False).apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1: 2380 rows saved to stratified_sample_1.csv\n",
            "Sample 2: 2380 rows saved to stratified_sample_2.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2728491562.py:35: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  stratified_sample = df.groupby(\"strat_key\", group_keys=False).apply(\n"
          ]
        }
      ],
      "source": [
        "# PART 1: STRATIFIED RANDOM SAMPLING\n",
        "\n",
        "# This script performs stratified random sampling on Vietnamese census data\n",
        "# and calculates population risk scores for privacy analysis\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# PART 1: STRATIFIED RANDOM SAMPLING\n",
        "\n",
        "# Load the Vietnamese census dataset (2019)\n",
        "df = pd.read_csv(\"nswiss2011.csv\", on_bad_lines='skip')\n",
        "\n",
        "# Define the stratification variables (quasi-identifiers)\n",
        "strat_cols = [\"persons\", \"hhwt\", \"gq\", \"regionw\", \"ownershipd\"]\n",
        "\n",
        "# Set the sampling fraction (1% of the population)\n",
        "sample_fraction = 0.01\n",
        "\n",
        "# Create a unique stratification key by combining all stratification columns\n",
        "df[\"strat_key\"] = df[strat_cols].astype(str).agg(\"_\".join, axis=1)\n",
        "\n",
        "# Configuration for generating multiple samples\n",
        "num_samples = 2                    # Number of independent samples to generate\n",
        "random_seeds = [42, 43]           # Different seeds ensure different samples\n",
        "\n",
        "# Generate stratified samples\n",
        "print(\"Generating stratified samples...\")\n",
        "for i, seed in enumerate(random_seeds, start=1):\n",
        "\n",
        "    # Calculate target sample size (1% of total population)\n",
        "    sample_size = int(len(df) * sample_fraction)\n",
        "\n",
        "    # Perform stratified sampling within each stratum\n",
        "    # Each group (strat_key) contributes proportionally to its size\n",
        "    stratified_sample = df.groupby(\"strat_key\", group_keys=False).apply(\n",
        "        lambda g: g.sample(\n",
        "            n=max(1, round(len(g) * sample_fraction)),  # At least 1 record per stratum\n",
        "            random_state=seed\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Ensure exact sample size by random sampling from the stratified result\n",
        "    # This step handles any rounding discrepancies from the stratified sampling\n",
        "    stratified_sample = stratified_sample.sample(n=sample_size, random_state=seed)\n",
        "\n",
        "    # Remove the temporary stratification key column\n",
        "    stratified_sample = stratified_sample.drop(columns=\"strat_key\")\n",
        "\n",
        "    # Save sample to CSV file for further analysis\n",
        "    output_filename = f\"stratified_sample_{i}.csv\"\n",
        "    stratified_sample.to_csv(output_filename, index=False)\n",
        "\n",
        "    print(f\"Sample {i}: {len(stratified_sample)} rows saved to {output_filename}\")\n",
        "\n",
        "# Clean up: remove stratification key from original dataset\n",
        "df.drop(columns=\"strat_key\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 2: POPULATION RISK CALCULATION\n",
        "\n",
        "# Reload the original census data for risk analysis\n",
        "df = pd.read_csv(\"nswiss2011.csv\")\n",
        "\n",
        "# Define quasi-identifiers (same as stratification variables)\n",
        "key_vars = [\"persons\", \"hhwt\", \"gq\", \"regionw\", \"ownershipd\"]\n",
        "\n",
        "# Step 1: Create equivalence classes\n",
        "# Records with identical quasi-identifier values form an equivalence class\n",
        "df['eq_class'] = df[key_vars].astype(str).agg('-'.join, axis=1)\n",
        "\n",
        "# Step 2: Count the size of each equivalence class\n",
        "# Larger classes provide better privacy protection (lower re-identification risk)\n",
        "equiv_counts = df['eq_class'].value_counts()\n",
        "\n",
        "# Step 3: Map equivalence class sizes back to individual records\n",
        "# Each record gets labeled with its class size\n",
        "df['eq_class_size'] = df['eq_class'].map(equiv_counts)\n",
        "\n",
        "# Step 4: Calculate individual re-identification risk\n",
        "# Risk = 1 / class_size (smaller classes = higher individual risk)\n",
        "df['individual_risk'] = 1 / df['eq_class_size']\n",
        "\n",
        "# Step 5: Calculate total population risk\n",
        "# Sum of all individual risks across the entire population\n",
        "total_risk = df['individual_risk'].sum()\n",
        "\n",
        "# OUTPUT RESULTS\n",
        "print(f\"True Population Risk Score for Switzerland 2011: {total_risk:.4f}\")\n",
        "print(\"\\nSample of risk analysis results:\")\n",
        "print(df[['eq_class', 'eq_class_size', 'individual_risk']].head())\n",
        "\n",
        "# =============================================================================\n",
        "# INTERPRETATION NOTES:\n",
        "# - Higher total risk = greater privacy vulnerability across the population\n",
        "# - Individual risk of 1.0 = unique record (highest re-identification risk)\n",
        "# - Individual risk of 0.1 = part of 10-record equivalence class (lower risk)\n",
        "# ============================================================================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuqcyKAXLzXL",
        "outputId": "a9d97e37-537a-4dc0-91bb-fa8b68a59734"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Population Risk Score for Switzerland 2011: 15061.0000\n",
            "\n",
            "Sample of risk analysis results:\n",
            "            eq_class  eq_class_size  individual_risk\n",
            "0  1-17.04-10-44-210             35         0.028571\n",
            "1  1-17.89-10-44-210             96         0.010417\n",
            "2  1-31.99-10-44-210             13         0.076923\n",
            "3  1-10.22-10-44-210             82         0.012195\n",
            "4   1-12.6-10-44-100             27         0.037037\n"
          ]
        }
      ]
    }
  ]
}